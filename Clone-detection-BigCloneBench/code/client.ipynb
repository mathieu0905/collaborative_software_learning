{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    output_dir = \"./saved_models\"\n",
    "    model_type = \"roberta\"\n",
    "    config_name = \"../../../model/codebert-base/config.json\"\n",
    "    model_name_or_path = \"../../../model/codebert-base\"\n",
    "    tokenizer_name = \"../../../model/codebert-base\"\n",
    "    train_data_dir = \"../../tags/splits_even/\"\n",
    "    eval_data_file = \"../../dataset/valid.txt\"\n",
    "    test_data_file = \"../../dataset/test.txt\"\n",
    "    epoch = 2\n",
    "    block_size = 400\n",
    "    train_batch_size = 16\n",
    "    eval_batch_size = 32\n",
    "    learning_rate = 5e-5\n",
    "    max_grad_norm = 1.0\n",
    "    seed = 123456\n",
    "    # 以下是没有明确提供的参数，我将使用默认值\n",
    "    mlm = False\n",
    "    mlm_probability = 0.15\n",
    "    cache_dir = \"\"\n",
    "    gradient_accumulation_steps = 1\n",
    "    adam_epsilon = 1e-8\n",
    "    max_steps = -1\n",
    "    warmup_steps = 0\n",
    "    logging_steps = 50\n",
    "    eval_all_checkpoints = False\n",
    "    no_cuda = False\n",
    "    overwrite_output_dir = False\n",
    "    overwrite_cache = False\n",
    "    fp16 = False\n",
    "    fp16_opt_level = 'O1'\n",
    "    local_rank = -1\n",
    "    server_ip = ''\n",
    "    server_port = ''\n",
    "    do_lower_case = ''\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from centralized import load_data, load_model, train, evaluate, DEVICE, parse_args\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "import ray\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='training.log', level=logging.INFO)\n",
    "\n",
    "def set_parameters(model, parameters):\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "logging.info(\"Loading model\")\n",
    "\n",
    "try:\n",
    "    model, args = load_model(args)\n",
    "    logging.info(\"Loading model succesfully\")\n",
    "except Exception as e:\n",
    "    logging.error(e)\n",
    "\n",
    "args.n_gpu = 1\n",
    "args.per_gpu_train_batch_size=args.train_batch_size//args.n_gpu\n",
    "args.per_gpu_eval_batch_size=args.eval_batch_size//args.n_gpu\n",
    "args.device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainset, testset, cid):\n",
    "        self.model = model\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "        self.cid = cid\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        train(args, self.model, self.trainset, self.cid)\n",
    "        return self.get_parameters({}), len(self.trainset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        eval_loss, result = evaluate(args, self.model, self.testset)\n",
    "        return eval_loss, len(self.testset), result\n",
    "    \n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    logging.info(f\"Client {cid} is starting training...\")\n",
    "    \n",
    "    trainset, testset = load_data(cid=cid, args=args)\n",
    "\n",
    "    print(len(testset))\n",
    "\n",
    "    # Create a client-specific Flower client\n",
    "    return FlowerClient(model, trainset, testset, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1: 90103\n",
      "split_1: 9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9010/9010 [00:07<00:00, 1238.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 415416\n",
      "valid: 41541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41541/41541 [00:11<00:00, 3524.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.FlowerClient at 0x7efb25406620>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFedAvg(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(self, rnd, results, failures):\n",
    "        logging.info(f\"Server: Aggregating parameters in round {rnd}\")\n",
    "        aggregated_parameters = super().aggregate_fit(rnd, results, failures)\n",
    "        if aggregated_parameters is not None:\n",
    "            logging.info(\"Server: Parameters aggregated successfully\")\n",
    "        else:\n",
    "            logging.info(\"Server: Parameter aggregation failed\")\n",
    "        return aggregated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "client_resources = {\"num_cpus\": 8, \"num_gpus\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl.simulation.start_simulation(\n",
    "#     client_fn=client_fn,\n",
    "#     num_clients=NUM_CLIENTS,\n",
    "#     config=fl.server.ServerConfig(num_rounds=2),\n",
    "#     client_resources=client_resources,\n",
    "#     strategy=CustomFedAvg()\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
